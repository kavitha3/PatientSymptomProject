{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#PATIENT SYMPTOM ANALYZER EASYGUI\n",
    "from easygui import *\n",
    "import csv\n",
    "import time\n",
    "import metapy\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from time import strptime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#################### GET MRN FROM USER ###############################\n",
    "msg = \"Enter MRN:\"\n",
    "title = \"Patient Lookup\"\n",
    "fieldNames = [\"MRN\"]\n",
    "fieldValues = []  # we start with blanks for the values\n",
    "fieldValues = multenterbox(msg,title, fieldNames)\n",
    "\n",
    "# make sure that none of the fields was left blank\n",
    "while 1:\n",
    "    if fieldValues == None: break\n",
    "    errmsg = \"\"\n",
    "    for i in range(len(fieldNames)):\n",
    "      if fieldValues[i].strip() == \"\":\n",
    "        errmsg = errmsg + ('\"%s\" is a required field.\\n\\n' % fieldNames[i])\n",
    "    if errmsg == \"\": break # no problems found\n",
    "    fieldValues = multenterbox(errmsg, title, fieldNames, fieldValues)\n",
    "    \n",
    "#################### GET MRN FROM USER ###############################  \n",
    "\n",
    "\n",
    "\n",
    "def tokenize_doc(doc):\n",
    "    #tok = metapy.analyzers.ICUTokenizer(suppress_tags = True)\n",
    "    tok = metapy.analyzers.ICUTokenizer()\n",
    "    tok = metapy.analyzers.LowercaseFilter(tok)\n",
    "    tok.set_content(doc_notes.content()) ##tok = tokenized sentence (each individual word in order)\n",
    "    return(tok)\n",
    "\n",
    "def negation_detection(word, num_words, tok):\n",
    "    negation = False\n",
    "    tokens = [token for token in tok]\n",
    "    for i in range(len(tokens)):\n",
    "        if num_words == 1:\n",
    "            if tokens[i] == word:\n",
    "                c = i-1;\n",
    "                while (c >0 and i-c <= 15 and (tokens[c] != '<s>' and tokens[c] != ':' and tokens[c] != '-' and tokens[c] != ';')): \n",
    "                    for negation_word in negation_list:\n",
    "                        if tokens[c] == negation_word['Negation']:\n",
    "                            #print(tokens[c], i, ' ', c)\n",
    "                            negation = True\n",
    "                            return(negation)\n",
    "\n",
    "                    c=c-1\n",
    "                if ((i+4) < len(tokens)) and (tokens[i+1] == 'screening' or tokens[i+2] == 'screening' or tokens[i+3] == 'screening' or tokens[i+1] == 'exam' or tokens[i+2] == 'exam' or  tokens[i+3] == 'exam' or tokens[i+1] == 'education' or tokens[i+2] == 'education' or tokens[i+3] == 'education'):\n",
    "                    negation = True\n",
    "                    return(negation)\n",
    "        if (num_words == 2 and (i+1) < len(tokens)):\n",
    "            if (tokens[i] + ' ' + tokens[i+1]) == word:\n",
    "                c = i-1;\n",
    "                while (c >0 and i-c <= 15 and (tokens[c] != '<s>' and tokens[c] != ':' and tokens[c] != '-' and tokens[c] != ';')): \n",
    "                    for negation_word in negation_list:\n",
    "                        if tokens[c] == negation_word['Negation']:\n",
    "                            #print(tokens[c], i, ' ', c)\n",
    "                            negation = True\n",
    "                            return(negation)\n",
    "                    c=c-1\n",
    "                if ((i+5) < len(tokens)) and (tokens[i+2] == 'screening' or tokens[i+3] == 'screening' or tokens[i+4] == 'screening' or tokens[i+2] == 'exam' or tokens[i+3] == 'exam' or  tokens[i+4] == 'exam' or tokens[i+2] == 'education' or tokens[i+3] == 'education' or tokens[i+4] == 'education'):\n",
    "                    negation = True\n",
    "                    return(negation)\n",
    "        if (num_words == 3 and (i+2) < len(tokens)):\n",
    "            if (tokens[i] + ' ' + tokens[i+1] + ' ' + tokens[i+2]) == word:\n",
    "                c = i-1;\n",
    "                while (c >0 and i-c <= 15 and (tokens[c] != '<s>' and tokens[c] != ':' and tokens[c] != '-' and tokens[c] != ';')): \n",
    "                    for negation_word in negation_list:\n",
    "                        if tokens[c] == negation_word['Negation']:\n",
    "                            #print(tokens[c], i, ' ', c)\n",
    "                            negation = True\n",
    "                            return(negation)\n",
    "                    c=c-1\n",
    "                if ((i+6) < len(tokens)) and (tokens[i+3] == 'screening' or tokens[i+4] == 'screening' or tokens[i+5] == 'screening' or tokens[i+3] == 'exam' or tokens[i+4] == 'exam' or  tokens[i+5] == 'exam' or tokens[i+3] == 'education' or tokens[i+4] == 'education' or tokens[i+5] == 'education'):\n",
    "                    negation = True\n",
    "                    return(negation)\n",
    "        if (num_words == 4 and (i+1) < len(tokens)):\n",
    "            if (tokens[i] + ' ' + tokens[i+1] + ' ' + tokens[i+2] + ' ' + tokens[i+3]) == word:\n",
    "                c = i-1;\n",
    "                while (c >0 and i-c <= 15 and (tokens[c] != '<s>' and tokens[c] != ':' and tokens[c] != '-' and tokens[c] != ';')): \n",
    "                    for negation_word in negation_list:\n",
    "                        if tokens[c] == negation_word['Negation']:\n",
    "                            #print(tokens[c], i, ' ', c)\n",
    "                            negation = True\n",
    "                            return(negation)\n",
    "                    c=c-1\n",
    "                if ((i+7) < len(tokens)) and (tokens[i+4] == 'screening' or tokens[i+5] == 'screening' or tokens[i+6] == 'screening' or tokens[i+4] == 'exam' or tokens[i+5] == 'exam' or  tokens[i+6] == 'exam' or tokens[i+4] == 'education' or tokens[i+5] == 'education' or tokens[i+6] == 'education'):\n",
    "                    negation = True\n",
    "                    return(negation)\n",
    "                \n",
    "  \n",
    "                \n",
    "  \n",
    "\n",
    " #       if tokens[i] == word:\n",
    " #           if tokens[i-1] == 'denies':\n",
    " #               negation = True\n",
    " #               break            \n",
    "    return(negation)\n",
    "\n",
    "def build_rel_symptom_list(keys, num_words, doc):\n",
    "    for key in keys:\n",
    "        for symptom in symptom_list:\n",
    "            if key == symptom['Symptom'].lower():\n",
    "                #print(key)\n",
    "                \n",
    "                tok = tokenize_doc(doc)\n",
    "                if negation_detection(keys[key], num_words, tok) == False:\n",
    "                    rel_symptoms.append(key)\n",
    "    return()\n",
    "\n",
    "def unigram(doc):\n",
    "    #keys = []\n",
    "    keys = {}\n",
    "    \n",
    "    #word_part = []\n",
    "    tok = tokenize_doc(doc) #tokenize document\n",
    "    ana = metapy.analyzers.NGramWordAnalyzer(1,tok)  #stores results in tuples\n",
    "    Ngrams = ana.analyze(doc_notes)\n",
    "    for word in Ngrams:\n",
    "        word_combination = word\n",
    "        #keys.append(word_combination)\n",
    "        keys[word] = word_combination\n",
    "    build_rel_symptom_list(keys, 1, doc)\n",
    "        \n",
    "    return()    \n",
    "\n",
    "def bigrams(doc):\n",
    "    #keys = []\n",
    "    keys = {}\n",
    "    #word_part = []\n",
    "    tok = tokenize_doc(doc) #tokenize document\n",
    "    ana = metapy.analyzers.NGramWordAnalyzer(2,tok)  #stores results in tuples\n",
    "    Ngrams = ana.analyze(doc_notes)\n",
    "    for word in Ngrams:\n",
    "        word_combination = word[0] + \" \" + word[1]\n",
    "        #word_part.append(word[0])\n",
    "        #keys.append(word_combination)\n",
    "        keys[word_combination] = word_combination\n",
    "    build_rel_symptom_list(keys, 2, doc)\n",
    "        \n",
    " \n",
    "    return()\n",
    "\n",
    "def trigrams(doc):\n",
    "    #keys = []\n",
    "    keys = {}\n",
    "    #word_part = []\n",
    "    tok = tokenize_doc(doc) #tokenize document\n",
    "    ana = metapy.analyzers.NGramWordAnalyzer(3,tok)  #stores results in tuples\n",
    "    Ngrams = ana.analyze(doc_notes)\n",
    "    for word in Ngrams:\n",
    "        word_combination = word[0] + \" \" + word[1] + \" \" + word[2]\n",
    "        #word_part.append(word[0])\n",
    "        #keys.append(word_combination)\n",
    "        keys[word_combination] = word_combination\n",
    "    build_rel_symptom_list(keys, 3, doc)\n",
    " \n",
    "            \n",
    "    return()\n",
    "\n",
    "def quadgrams(doc):\n",
    "   #keys = []\n",
    "    keys = {}\n",
    "    #word_part = []\n",
    "    tok = tokenize_doc(doc) #tokenize document\n",
    "    ana = metapy.analyzers.NGramWordAnalyzer(4,tok)  #stores results in tuples\n",
    "    Ngrams = ana.analyze(doc_notes)\n",
    "    for word in Ngrams:\n",
    "        word_combination = word[0] + \" \" + word[1] + \" \" + word[2] + \" \" + word[3]\n",
    "        #word_part.append(word[0])\n",
    "        #keys.append(word_combination)\n",
    "        keys[word_combination] = word_combination\n",
    "    build_rel_symptom_list(keys, 4, doc)\n",
    "        \n",
    "\n",
    "            \n",
    "    return()\n",
    "\n",
    "\n",
    "#open files symptoms.csv and store data in symptom_list\n",
    "symptom_list = []\n",
    "patient_list = []\n",
    "negation_list = []\n",
    "keys = [] #holds the keys that result in the NGramWordAnalyzer result\n",
    "word_combination = \"\" #stores each tuple combination as phrase\n",
    "rel_symptoms = []\n",
    "with open('symptoms.csv','r') as csv_file:\n",
    "    symptom_reader = csv.DictReader(csv_file)\n",
    "    for row in symptom_reader:\n",
    "        symptom_list.append(row)\n",
    "\n",
    "#open files  patient_list.csv adn store data in patient_list\n",
    "with open('patient_list.csv','r') as csv_file:\n",
    "    patient_reader = csv.DictReader(csv_file)\n",
    "    for row in patient_reader:\n",
    "        patient_list.append(row)\n",
    "        \n",
    "#open files negation.csv and store data in negation_list\n",
    "with open('negation.csv','r') as csv_file:\n",
    "    negation_reader = csv.DictReader(csv_file)\n",
    "    for row in negation_reader:\n",
    "        negation_list.append(row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#convert date from string to date\n",
    "\n",
    "for patient in patient_list:\n",
    "    DOS = patient['Date of Visit']\n",
    "    DOB = patient['DOB']\n",
    "    patient['Date of Visit'] = datetime.strptime(DOS, \"%m/%d/%Y\")\n",
    "    patient['DOB'] = datetime.strptime(DOB, \"%m/%d/%Y\")\n",
    "    \n",
    "#pull patient of interest (eventually inputted by user) and pull DOS within last year: \n",
    "  #store data in patient_of_interest\n",
    "if fieldValues != None:\n",
    "    mrn = fieldValues[0]\n",
    "    \n",
    "patient_of_interest = []\n",
    "for patient in patient_list:   \n",
    "    if patient['Patient ID'] == mrn and (patient['Date of Visit'] > (datetime.now() - relativedelta(years=1))):\n",
    "        patient_of_interest.append(patient)\n",
    "#########Check if patient exists#############\n",
    "patient_exists = []\n",
    "for patient in patient_list:   \n",
    "    if patient['Patient ID'] == mrn:\n",
    "        patient_exists.append(patient)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# Loop through each encounter to generate a list of relevant symptoms     \n",
    "for patient in patient_of_interest:\n",
    "    doc_notes = metapy.index.Document()\n",
    "    doc_notes.content(patient['Notes'])\n",
    "    unigram(doc_notes)\n",
    "    bigrams(doc_notes)\n",
    "    trigrams(doc_notes)\n",
    "    quadgrams(doc_notes)\n",
    "\n",
    "#compile relevant symptoms\n",
    "dict_symptoms = dict.fromkeys(rel_symptoms)\n",
    "for symptom1 in rel_symptoms:\n",
    "    symptom_count = 0\n",
    "    for symptom in rel_symptoms:\n",
    "        if symptom1 == symptom:\n",
    "            symptom_count = symptom_count+1\n",
    "        dict_symptoms[symptom1] = symptom_count\n",
    "\n",
    "#sort symptoms\n",
    "sorted_symptoms = sorted(dict_symptoms, key=lambda x: dict_symptoms[x], reverse=True)\n",
    "\n",
    "f=open(\"results.txt\",\"w\")\n",
    "   \n",
    "#Print Patient Summary\n",
    "if(len(patient_of_interest) == 0 and len(patient_exists) > 0):\n",
    "    f.write(\"Patient was not seen in the last year.\\n\")\n",
    "elif (len(patient_of_interest) == 1):    \n",
    "    for patient in patient_of_interest:\n",
    "        f.write(\"Patient summary:\\n\")\n",
    "        f.write(\"Name: {}\".format(patient['Patient Name']))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"Gender: {}\".format(patient['Gender']))\n",
    "        f.write(\"\\n\")\n",
    "        if (patient['DOB'].year > date.today().year):\n",
    "            f.write(\"Age: {} years\\n\\n\".format(date.today().year - (patient['DOB'].year - 100)))\n",
    "        else:\n",
    "            f.write(\"Age: {} years\\n\\n\".format(date.today().year - (patient['DOB'].year)))\n",
    "        break\n",
    "    \n",
    "    f.write(\"{} was seen once in the last year.\\n\\n\".format(patient['Patient Name']))\n",
    "    f.write(\"Key symptoms/conditions treated were:\\n\")\n",
    "    for symptoms in sorted_symptoms:\n",
    "        if (dict_symptoms[symptoms] == 1):\n",
    "            f.write(\"-{} {} time.\\n\".format(symptoms, dict_symptoms[symptoms]))\n",
    "        if (dict_symptoms[symptoms] > 1):\n",
    "            f.write(\"-{} {} times.\\n\".format(symptoms, dict_symptoms[symptoms]))\n",
    "    \n",
    "    \n",
    "else:\n",
    "    for patient in patient_of_interest:\n",
    "        f.write(\"Patient summary:\\n\")\n",
    "        f.write(\"Name: {}\".format(patient['Patient Name']))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"Gender: {}\".format(patient['Gender']))\n",
    "        f.write(\"\\n\")\n",
    "        if (patient['DOB'].year > date.today().year):\n",
    "            f.write(\"Age: {} years\\n\\n\".format(date.today().year - (patient['DOB'].year - 100)))\n",
    "        else:\n",
    "            f.write(\"Age: {} years\\n\\n\".format(date.today().year - (patient['DOB'].year)))\n",
    "        break\n",
    "\n",
    "    f.write(\"{} was seen {} times in the last year.\\n\\n\".format(patient['Patient Name'],len(patient_of_interest)))\n",
    "    f.write(\"Key symptoms/conditions treated were:\\n\")\n",
    "    #print(\"{} was seen {} times in the last year.\".format(patient['Patient Name'],len(patient_of_interest)))\n",
    "    #print(\"Key symptoms/conditions treated were:\")\n",
    "    for symptoms in sorted_symptoms:\n",
    "        if (dict_symptoms[symptoms] == 1):\n",
    "            f.write(\"-{} {} time.\\n\".format(symptoms, dict_symptoms[symptoms]))\n",
    "        if (dict_symptoms[symptoms] > 1):\n",
    "            f.write(\"-{} {} times.\\n\".format(symptoms, dict_symptoms[symptoms]))\n",
    "            \n",
    "f.close()\n",
    "\n",
    "######## DISPLAY IN EASYGUI############\n",
    "if fieldValues != None and len(patient_exists)>0:\n",
    "    filename = \"results.txt\"\n",
    "    f = open(filename, \"r\")\n",
    "    text = f.readlines()\n",
    "    f.close()\n",
    "    codebox(\"\", \"\", text)\n",
    "######## DISPLAY IN EASYGUI############\n",
    "if fieldValues == None:\n",
    "    codebox(\"\", \"\", \"MRN was not entered.\")\n",
    "if len(patient_exists) == 0:\n",
    "    codebox(\"\", \"\", \"MRN is not valid.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
